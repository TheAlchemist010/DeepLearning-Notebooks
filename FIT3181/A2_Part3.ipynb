{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5b6b5b7dcc1f4d49a52ca018b3c1aa94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf22352ebdc643c7823f31099974d223",
              "IPY_MODEL_97dbbe60ffea4dd9aa096db80e99e784",
              "IPY_MODEL_5f97e8f1116b406991598556266c4344"
            ],
            "layout": "IPY_MODEL_3ec0378f23df4117b039103ed54e1c1e"
          }
        },
        "bf22352ebdc643c7823f31099974d223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0eba2e87478244c9b7dd85e625e4a5ea",
            "placeholder": "​",
            "style": "IPY_MODEL_af61bd3f0ddd488faa52d45fb70f7658",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "97dbbe60ffea4dd9aa096db80e99e784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86c37712aa3d408baac9125e25c5505f",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d5f95c9268845cb91f0b8828e89fe4c",
            "value": 48
          }
        },
        "5f97e8f1116b406991598556266c4344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32646943dd4643d7886dc5b14fe9c573",
            "placeholder": "​",
            "style": "IPY_MODEL_e95e1a4751b84ca3b682a356e2bf378e",
            "value": " 48.0/48.0 [00:00&lt;00:00, 1.01kB/s]"
          }
        },
        "3ec0378f23df4117b039103ed54e1c1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eba2e87478244c9b7dd85e625e4a5ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af61bd3f0ddd488faa52d45fb70f7658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86c37712aa3d408baac9125e25c5505f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d5f95c9268845cb91f0b8828e89fe4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32646943dd4643d7886dc5b14fe9c573": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e95e1a4751b84ca3b682a356e2bf378e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cf273847b324845bfad7f97bca47e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b65c66c5fbe4bf78c356061c873e084",
              "IPY_MODEL_a91604e47de64a3d8ce3a1f474deadc3",
              "IPY_MODEL_4bab26f21e6b474e94f9663c40be3330"
            ],
            "layout": "IPY_MODEL_798334d7162048ab86e0dd12612aedbf"
          }
        },
        "0b65c66c5fbe4bf78c356061c873e084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d2f008c02b14f37b8b25216b9cd92c8",
            "placeholder": "​",
            "style": "IPY_MODEL_bdbfacd5586f4082a75120f2d995765a",
            "value": "vocab.txt: 100%"
          }
        },
        "a91604e47de64a3d8ce3a1f474deadc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f6c250ecbcd4a8daa9507217443f558",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af9c2a93148d48aca4fe4609e4bf2808",
            "value": 231508
          }
        },
        "4bab26f21e6b474e94f9663c40be3330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb9ac402406445c49f953d30f56156f0",
            "placeholder": "​",
            "style": "IPY_MODEL_607169f228734f63ad3512a89c5fea7f",
            "value": " 232k/232k [00:00&lt;00:00, 3.00MB/s]"
          }
        },
        "798334d7162048ab86e0dd12612aedbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d2f008c02b14f37b8b25216b9cd92c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdbfacd5586f4082a75120f2d995765a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f6c250ecbcd4a8daa9507217443f558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af9c2a93148d48aca4fe4609e4bf2808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb9ac402406445c49f953d30f56156f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "607169f228734f63ad3512a89c5fea7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a27bf766e3554330b71f30be7faefcdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e8df6e57e8f4f43ae4333c9aa656af3",
              "IPY_MODEL_73f443b9b4544ef9ba4b5333e52b07de",
              "IPY_MODEL_28d4ca1eb49b414eb9b85f8a7b5f1984"
            ],
            "layout": "IPY_MODEL_8516bceece4648e7b70debac689c2c00"
          }
        },
        "7e8df6e57e8f4f43ae4333c9aa656af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cd5cc22407144d19400ba055c85befe",
            "placeholder": "​",
            "style": "IPY_MODEL_f3f6b6977f7d420787687e204d36bf28",
            "value": "tokenizer.json: 100%"
          }
        },
        "73f443b9b4544ef9ba4b5333e52b07de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f930aca6b55e47fab7a3d05b14e86dd4",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_007f84d831da4c42a87e399249a2e28b",
            "value": 466062
          }
        },
        "28d4ca1eb49b414eb9b85f8a7b5f1984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24b59e02dc6b4a8e98de9ba098dd6b98",
            "placeholder": "​",
            "style": "IPY_MODEL_80b8a619406e4432a9061fa0c2f7598e",
            "value": " 466k/466k [00:00&lt;00:00, 4.14MB/s]"
          }
        },
        "8516bceece4648e7b70debac689c2c00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cd5cc22407144d19400ba055c85befe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3f6b6977f7d420787687e204d36bf28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f930aca6b55e47fab7a3d05b14e86dd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "007f84d831da4c42a87e399249a2e28b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24b59e02dc6b4a8e98de9ba098dd6b98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80b8a619406e4432a9061fa0c2f7598e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa8ae0f498f9408a858e4e5855abd46a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7e2a074b7b348d8a9b1e2fa18a1d521",
              "IPY_MODEL_7b2a425827d64ac5a12529512a56ec33",
              "IPY_MODEL_573f5f1b9ac2414993666e8640192712"
            ],
            "layout": "IPY_MODEL_f3426db8f2634d03822425170b79a6be"
          }
        },
        "c7e2a074b7b348d8a9b1e2fa18a1d521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d95fc22b6b742ae9b0ddc00ffacbd65",
            "placeholder": "​",
            "style": "IPY_MODEL_a693f29fe27c4feb92477b261527704d",
            "value": "config.json: 100%"
          }
        },
        "7b2a425827d64ac5a12529512a56ec33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f78dc47fe0244ab7b4064f3f24c53bbe",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_393a498f74534c979bc2f2ac29566927",
            "value": 570
          }
        },
        "573f5f1b9ac2414993666e8640192712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_041ad02b95624944a18859429b159cb2",
            "placeholder": "​",
            "style": "IPY_MODEL_a48cc5141bc14a1083ca7202ef4e3ed8",
            "value": " 570/570 [00:00&lt;00:00, 14.2kB/s]"
          }
        },
        "f3426db8f2634d03822425170b79a6be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d95fc22b6b742ae9b0ddc00ffacbd65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a693f29fe27c4feb92477b261527704d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f78dc47fe0244ab7b4064f3f24c53bbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "393a498f74534c979bc2f2ac29566927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "041ad02b95624944a18859429b159cb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a48cc5141bc14a1083ca7202ef4e3ed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eccdad491e284a74ba6005a6fd511128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b844ce6ecb88459990d6c6fe5445812b",
              "IPY_MODEL_ccdea0e274814da4ac9d6c9f5b05f541",
              "IPY_MODEL_a6b7e08deab548c5944bb69f9cf288e8"
            ],
            "layout": "IPY_MODEL_505dec7196654dc290ce103b57fb5d9b"
          }
        },
        "b844ce6ecb88459990d6c6fe5445812b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b395be123db449a19b8ebd416962729d",
            "placeholder": "​",
            "style": "IPY_MODEL_b8a6801026a74641a6904ac24fac4ca3",
            "value": "Map: 100%"
          }
        },
        "ccdea0e274814da4ac9d6c9f5b05f541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_812ff4a6481e45dc9cb6ac192eda9867",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6e2cf5cf6fd4cb288b817a9cd25fb95",
            "value": 2000
          }
        },
        "a6b7e08deab548c5944bb69f9cf288e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa060231ea8d401dbfd132d4f3fa0040",
            "placeholder": "​",
            "style": "IPY_MODEL_c53ec3a0072f48278cee76016a921992",
            "value": " 2000/2000 [00:00&lt;00:00, 8991.12 examples/s]"
          }
        },
        "505dec7196654dc290ce103b57fb5d9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b395be123db449a19b8ebd416962729d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8a6801026a74641a6904ac24fac4ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "812ff4a6481e45dc9cb6ac192eda9867": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6e2cf5cf6fd4cb288b817a9cd25fb95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa060231ea8d401dbfd132d4f3fa0040": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c53ec3a0072f48278cee76016a921992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheAlchemist010/DeepLearning-Notebooks/blob/main/FIT3181/A2_Part3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"#0b486b\">  FIT3181: Deep Learning (2024) - Assignment 2 (Transformers)</font>\n",
        "***\n",
        "*CE/Lecturer (Clayton):*  **Dr Trung Le** | trunglm@monash.edu <br/>\n",
        "*Lecturer (Clayton):* **Prof Dinh Phung** | dinh.phung@monash.edu <br/>\n",
        "*Lecturer (Malaysia):*  **Dr Arghya Pal** | arghya.pal@monash.edu <br/>\n",
        "*Lecturer (Malaysia):*  **Dr Lim Chern Hong** | lim.chernhong@monash.edu <br/>  <br/>\n",
        "*Head Tutor 3181:*  **Miss Vy Vo** |  \\[v.vo@monash.edu \\] <br/>\n",
        "*Head Tutor 5215:*  **Dr Van Nguyen** |  \\[van.nguyen1@monash.edu \\]\n",
        "\n",
        "<br/> <br/>\n",
        "Faculty of Information Technology, Monash University, Australia\n",
        "***"
      ],
      "metadata": {
        "id": "qEHyseHxA8q4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"#0b486b\">  Student Information</font>\n",
        "***\n",
        "Surname: **Gallagher**  <br/>\n",
        "Firstname: **Daniel**    <br/>\n",
        "Student ID: **33094969**    <br/>\n",
        "Email: **dgal0013@student.monash.edu**    <br/>\n",
        "Your tutorial time: **Monday 4pm**    <br/>\n",
        "***"
      ],
      "metadata": {
        "id": "QqMi8gdDBD1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"0b486b\">Assignment 2 – Deep Learning for Sequential Data</font>\n",
        "### Due: <font color=\"red\">11:55pm Sunday, 27 October 2024</font> (FIT3181)\n",
        "\n",
        "#### <font color=\"red\">Important note:</font> This is an **individual** assignment. It contributes **15%** to your final mark. Read the assignment instructions carefully."
      ],
      "metadata": {
        "id": "BLGpdQp2BPOU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#0b486b\">Assignment 2's Organization</font>\n",
        "This assignment 2 has two (2) sections:\n",
        "- Section 1: Fundamentals of RNNs (10 marks).\n",
        "- Section 2: Deep Learning for Sequential Data (90 marks). This section is further divided into 4 parts.\n",
        "\n",
        "The assignment 2 is organized in three (3) notebooks.\n",
        "- Notebook 1 ([link](https://colab.research.google.com/drive/1Rm2wWOJCjilpVf4T6RJZFtkjRULuTo0g?usp=sharing)) [Total: 30 marks] includes Section 1 as well as Part 1 and Part 2 of Section 2.\n",
        "- Notebook 2 ([link](https://colab.research.google.com/drive/19-WnvLH24yUZ_eih3_8P_Fjn8cM8X2Gz?usp=sharing)) [Total: 40 marks] includes Part 3 of Section 2.\n",
        "- Notebook 3 (this notebook) [Total: 30 marks] includes Part 4 of Section 2.\n"
      ],
      "metadata": {
        "id": "PF8vqRzTCEsm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#0b486b\">What to submit</font>\n",
        "\n",
        "This assignment is to be completed individually and submitted to Moodle unit site. **By the due date, you are required to submit one  <font color=\"red; font-weight:bold\">single zip file, named xxx_assignment02_solution.zip</font> where `xxx` is your student ID, to the corresponding Assignment (Dropbox) in Moodle**. You can use Google Colab to do Assignment 2 but you need to save it to an `*.ipynb` file to submit to the unit Moodle.\n",
        "\n",
        "**More importantly, if you use Google Colab to do this assignment, you need to first make a copy of this notebook on your Google drive**."
      ],
      "metadata": {
        "id": "UbY5tyqK37Iw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***For example, if your student ID is <font color=\"red; font-weight:bold\">12356</font>, then gather all of your assignment solutions to a folder, create a zip file named <font color=\"red; font-weight:bold\">123456_assignment02_solution.zip</font> and submit this file.***"
      ],
      "metadata": {
        "id": "cg1MdTwq37I6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Within this zip folder, you **must** submit the following files <u>for each part</u>:\n",
        "1.\t**`FIT3181_DeepLearning_Assignment2_Official[Main].ipynb`**:  this is your Python notebook solution source file.\n",
        "1.\t**`FIT3181_DeepLearning_Assignment2_Official[Main].html`**: this is the output of your Python notebook solution *exported* in HTML format.\n",
        "1. **`FIT3181_DeepLearning_Assignment2_Official[RNNs].ipynb`**\n",
        "1. **`FIT3181_DeepLearning_Assignment2_Official[RNNs].html`**\n",
        "1. **`FIT3181_DeepLearning_Assignment2_Official[Transformers].ipynb`**\n",
        "1. **`FIT3181_DeepLearning_Assignment2_Official[Transformers].html`**\n",
        "1.\tAny **extra files or folder** needed to complete your assignment (e.g., images used in your answers).\n",
        "\n"
      ],
      "metadata": {
        "id": "prEJdUhB37I6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2: Deep Learning for Sequential Data"
      ],
      "metadata": {
        "id": "rAVPM0BnTdd4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=\"#0b486b\">Set random seeds</font>"
      ],
      "metadata": {
        "id": "FAgUSME4TsCP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to install the package datasets for creating BERT datasets."
      ],
      "metadata": {
        "id": "5DaYHAIv4poj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7ik_46Y4vDo",
        "outputId": "3bb98093-d309-4229-e70f-2186c2560a7b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Downloading datasets-3.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.0.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start with importing PyTorch and NumPy and setting random seeds for PyTorch and NumPy. You can use any seeds you prefer."
      ],
      "metadata": {
        "id": "g6b0SM034sf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import random\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from transformers import BertTokenizer\n",
        "import os\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')"
      ],
      "metadata": {
        "id": "O7XWUry0JXCc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_all(seed=1029):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "seed_all(seed=1234)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "6ZoWqunmUY7L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#0b486b\">Download and preprocess the data</font>\n",
        "\n",
        "<div style=\"text-align: right\"><font color=\"red; font-weight:bold\"><span></div>"
      ],
      "metadata": {
        "id": "6VU1jS6SUl8q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset we use for this assignment is a question classification dataset for which the training set consists of $5,500$ questions belonging to 6 coarse question categories including:\n",
        "- abbreviation (ABBR),\n",
        "- entity (ENTY),\n",
        "- description (DESC),\n",
        "- human (HUM),\n",
        "- location (LOC) and\n",
        "- numeric (NUM).\n",
        "\n",
        "In this assignment, we will utilize a subset of this dataset, containing $2,000$ questions for training and validation. We will use 80% of those 2000 questions for trainning and the rest for validation.\n"
      ],
      "metadata": {
        "id": "wQEzWmZjUulL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing data is a crucial initial step in any machine learning or deep learning project. The *TextDataManager* class simplifies the process by providing functionalities to download and preprocess data specifically designed for the subsequent questions in this assignment. It is highly recommended to gain a comprehensive understanding of the class's functionality by **carefully reading** the content provided in the *TextDataManager* class before proceeding to answer the questions."
      ],
      "metadata": {
        "id": "zOd49RTpUxxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataManager:\n",
        "    \"\"\"\n",
        "    This class manages and preprocesses a simple text dataset for a sentence classification task.\n",
        "\n",
        "    Attributes:\n",
        "        verbose (bool): Controls verbosity for printing information during data processing.\n",
        "        max_sentence_len (int): The maximum length of a sentence in the dataset.\n",
        "        str_questions (list): A list to store the string representations of the questions in the dataset.\n",
        "        str_labels (list): A list to store the string representations of the labels in the dataset.\n",
        "        numeral_labels (list): A list to store the numerical representations of the labels in the dataset.\n",
        "        maxlen (int): Maximum length for padding sequences. Sequences longer than this length will be truncated,\n",
        "            and sequences shorter than this length will be padded with zeros. Defaults to 50.\n",
        "        numeral_data (list): A list to store the numerical representations of the questions in the dataset.\n",
        "        random_state (int): Seed value for random number generation to ensure reproducibility.\n",
        "            Set this value to a specific integer to reproduce the same random sequence every time. Defaults to 6789.\n",
        "        random (np.random.RandomState): Random number generator object initialized with the given random_state.\n",
        "            It is used for various random operations in the class.\n",
        "\n",
        "    Methods:\n",
        "        maybe_download(dir_name, file_name, url, verbose=True):\n",
        "            Downloads a file from a given URL if it does not exist in the specified directory.\n",
        "            The directory and file are created if they do not exist.\n",
        "\n",
        "        read_data(dir_name, file_names):\n",
        "            Reads data from files in a directory, preprocesses it, and computes the maximum sentence length.\n",
        "            Each file is expected to contain rows in the format \"<label>:<question>\".\n",
        "            The labels and questions are stored as string representations.\n",
        "\n",
        "        manipulate_data():\n",
        "            Performs data manipulation by tokenizing, numericalizing, and padding the text data.\n",
        "            The questions are tokenized and converted into numerical sequences using a tokenizer.\n",
        "            The sequences are padded or truncated to the maximum sequence length.\n",
        "\n",
        "        train_valid_test_split(train_ratio=0.9):\n",
        "            Splits the data into training, validation, and test sets based on a given ratio.\n",
        "            The data is randomly shuffled, and the specified ratio is used to determine the size of the training set.\n",
        "            The string questions, numerical data, and numerical labels are split accordingly.\n",
        "            TensorFlow `Dataset` objects are created for the training and validation sets.\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, verbose=True, random_state=6789):\n",
        "        self.verbose = verbose\n",
        "        self.max_sentence_len = 0\n",
        "        self.str_questions = list()\n",
        "        self.str_labels = list()\n",
        "        self.numeral_labels = list()\n",
        "        self.numeral_data = list()\n",
        "        self.random_state = random_state\n",
        "        self.random = np.random.RandomState(random_state)\n",
        "\n",
        "    @staticmethod\n",
        "    def maybe_download(dir_name, file_name, url, verbose=True):\n",
        "        if not os.path.exists(dir_name):\n",
        "            os.mkdir(dir_name)\n",
        "        if not os.path.exists(os.path.join(dir_name, file_name)):\n",
        "            urlretrieve(url + file_name, os.path.join(dir_name, file_name))\n",
        "        if verbose:\n",
        "            print(\"Downloaded successfully {}\".format(file_name))\n",
        "\n",
        "    def read_data(self, dir_name, file_names):\n",
        "        self.str_questions = list()\n",
        "        self.str_labels = list()\n",
        "        for file_name in file_names:\n",
        "            file_path= os.path.join(dir_name, file_name)\n",
        "            with open(file_path, \"r\", encoding=\"latin-1\") as f:\n",
        "                for row in f:\n",
        "                    row_str = row.split(\":\")\n",
        "                    label, question = row_str[0], row_str[1]\n",
        "                    question = question.lower()\n",
        "                    self.str_labels.append(label)\n",
        "                    self.str_questions.append(question[0:-1])\n",
        "                    if self.max_sentence_len < len(self.str_questions[-1]):\n",
        "                        self.max_sentence_len = len(self.str_questions[-1])\n",
        "\n",
        "        # turns labels into numbers\n",
        "        le = preprocessing.LabelEncoder()\n",
        "        le.fit(self.str_labels)\n",
        "        self.numeral_labels = np.array(le.transform(self.str_labels))\n",
        "        self.str_classes = le.classes_\n",
        "        self.num_classes = len(self.str_classes)\n",
        "        if self.verbose:\n",
        "            print(\"\\nSample questions and corresponding labels... \\n\")\n",
        "            print(self.str_questions[0:5])\n",
        "            print(self.str_labels[0:5])\n",
        "\n",
        "    def manipulate_data(self):\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        vocab = self.tokenizer.get_vocab()\n",
        "        self.word2idx = {w: i for i, w in enumerate(vocab)}\n",
        "        self.idx2word = {i:w for w,i in self.word2idx.items()}\n",
        "        self.vocab_size = len(self.word2idx)\n",
        "\n",
        "        token_ids = []\n",
        "        num_seqs = []\n",
        "        for text in self.str_questions:  # iterate over the list of text\n",
        "          text_seqs = self.tokenizer.tokenize(str(text))  # tokenize each text individually\n",
        "          # Convert tokens to IDs\n",
        "          token_ids = self.tokenizer.convert_tokens_to_ids(text_seqs)\n",
        "          # Convert token IDs to a tensor of indices using your word2idx mapping\n",
        "          seq_tensor = torch.LongTensor(token_ids)\n",
        "          num_seqs.append(seq_tensor)  # append the tensor for each sequence\n",
        "\n",
        "        # Pad the sequences and create a tensor\n",
        "        if num_seqs:\n",
        "          self.numeral_data = pad_sequence(num_seqs, batch_first=True)  # Pads to max length of the sequences\n",
        "          self.num_sentences, self.max_seq_len = self.numeral_data.shape\n",
        "\n",
        "    def train_valid_test_split(self, train_ratio=0.8, test_ratio = 0.1):\n",
        "        train_size = int(self.num_sentences*train_ratio) +1\n",
        "        test_size = int(self.num_sentences*test_ratio) +1\n",
        "        valid_size = self.num_sentences - (train_size + test_size)\n",
        "        data_indices = list(range(self.num_sentences))\n",
        "        random.shuffle(data_indices)\n",
        "        self.train_str_questions = [self.str_questions[i] for i in data_indices[:train_size]]\n",
        "        self.train_numeral_labels = self.numeral_labels[data_indices[:train_size]]\n",
        "        train_set_data = self.numeral_data[data_indices[:train_size]]\n",
        "        train_set_labels = self.numeral_labels[data_indices[:train_size]]\n",
        "        train_set_labels = torch.from_numpy(train_set_labels)\n",
        "        train_set = torch.utils.data.TensorDataset(train_set_data, train_set_labels)\n",
        "        self.test_str_questions = [self.str_questions[i] for i in data_indices[-test_size:]]\n",
        "        self.test_numeral_labels = self.numeral_labels[data_indices[-test_size:]]\n",
        "        test_set_data = self.numeral_data[data_indices[-test_size:]]\n",
        "        test_set_labels = self.numeral_labels[data_indices[-test_size:]]\n",
        "        test_set_labels = torch.from_numpy(test_set_labels)\n",
        "        test_set = torch.utils.data.TensorDataset(test_set_data, test_set_labels)\n",
        "        self.valid_str_questions = [self.str_questions[i] for i in data_indices[train_size:-test_size]]\n",
        "        self.valid_numeral_labels = self.numeral_labels[data_indices[train_size:-test_size]]\n",
        "        valid_set_data = self.numeral_data[data_indices[train_size:-test_size]]\n",
        "        valid_set_labels = self.numeral_labels[data_indices[train_size:-test_size]]\n",
        "        valid_set_labels = torch.from_numpy(valid_set_labels)\n",
        "        valid_set = torch.utils.data.TensorDataset(valid_set_data, valid_set_labels)\n",
        "        self.train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "        self.test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n",
        "        self.valid_loader = DataLoader(valid_set, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "_C2fuJNzUhha"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Loading data...')\n",
        "DataManager.maybe_download(\"data\", \"train_2000.label\", \"http://cogcomp.org/Data/QA/QC/\")\n",
        "\n",
        "dm = DataManager()\n",
        "dm.read_data(\"data/\", [\"train_2000.label\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3npdESj6Vb_t",
        "outputId": "402ffc6e-22f6-4745-e080-a88aa0647fc3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Downloaded successfully train_2000.label\n",
            "\n",
            "Sample questions and corresponding labels... \n",
            "\n",
            "['manner how did serfdom develop in and then leave russia ?', 'cremat what films featured the character popeye doyle ?', \"manner how can i find a list of celebrities ' real names ?\", 'animal what fowl grabs the spotlight after the chinese year of the monkey ?', 'exp what is the full form of .com ?']\n",
            "['DESC', 'ENTY', 'DESC', 'ENTY', 'ABBR']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dm.manipulate_data()\n",
        "dm.train_valid_test_split(train_ratio=0.8, test_ratio = 0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304,
          "referenced_widgets": [
            "5b6b5b7dcc1f4d49a52ca018b3c1aa94",
            "bf22352ebdc643c7823f31099974d223",
            "97dbbe60ffea4dd9aa096db80e99e784",
            "5f97e8f1116b406991598556266c4344",
            "3ec0378f23df4117b039103ed54e1c1e",
            "0eba2e87478244c9b7dd85e625e4a5ea",
            "af61bd3f0ddd488faa52d45fb70f7658",
            "86c37712aa3d408baac9125e25c5505f",
            "0d5f95c9268845cb91f0b8828e89fe4c",
            "32646943dd4643d7886dc5b14fe9c573",
            "e95e1a4751b84ca3b682a356e2bf378e",
            "4cf273847b324845bfad7f97bca47e87",
            "0b65c66c5fbe4bf78c356061c873e084",
            "a91604e47de64a3d8ce3a1f474deadc3",
            "4bab26f21e6b474e94f9663c40be3330",
            "798334d7162048ab86e0dd12612aedbf",
            "0d2f008c02b14f37b8b25216b9cd92c8",
            "bdbfacd5586f4082a75120f2d995765a",
            "2f6c250ecbcd4a8daa9507217443f558",
            "af9c2a93148d48aca4fe4609e4bf2808",
            "eb9ac402406445c49f953d30f56156f0",
            "607169f228734f63ad3512a89c5fea7f",
            "a27bf766e3554330b71f30be7faefcdf",
            "7e8df6e57e8f4f43ae4333c9aa656af3",
            "73f443b9b4544ef9ba4b5333e52b07de",
            "28d4ca1eb49b414eb9b85f8a7b5f1984",
            "8516bceece4648e7b70debac689c2c00",
            "8cd5cc22407144d19400ba055c85befe",
            "f3f6b6977f7d420787687e204d36bf28",
            "f930aca6b55e47fab7a3d05b14e86dd4",
            "007f84d831da4c42a87e399249a2e28b",
            "24b59e02dc6b4a8e98de9ba098dd6b98",
            "80b8a619406e4432a9061fa0c2f7598e",
            "fa8ae0f498f9408a858e4e5855abd46a",
            "c7e2a074b7b348d8a9b1e2fa18a1d521",
            "7b2a425827d64ac5a12529512a56ec33",
            "573f5f1b9ac2414993666e8640192712",
            "f3426db8f2634d03822425170b79a6be",
            "0d95fc22b6b742ae9b0ddc00ffacbd65",
            "a693f29fe27c4feb92477b261527704d",
            "f78dc47fe0244ab7b4064f3f24c53bbe",
            "393a498f74534c979bc2f2ac29566927",
            "041ad02b95624944a18859429b159cb2",
            "a48cc5141bc14a1083ca7202ef4e3ed8"
          ]
        },
        "id": "EgrYZPmyVj60",
        "outputId": "4f2887f5-ba25-4616-95e4-e787cf614d55"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b6b5b7dcc1f4d49a52ca018b3c1aa94"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cf273847b324845bfad7f97bca47e87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a27bf766e3554330b71f30be7faefcdf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa8ae0f498f9408a858e4e5855abd46a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in dm.train_loader:\n",
        "    print(x.shape, y.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH-U0sUMVnW-",
        "outputId": "a6ad4b69-3dc0-4668-a47f-baeff927d928"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 36]) torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now declare the `BaseTrainer` class, which will be used later to train the subsequent deep learning models for text data."
      ],
      "metadata": {
        "id": "lPPrm2_FHj-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class BaseTrainer:\n",
        "    def __init__(self, model, criterion, optimizer, train_loader, val_loader):\n",
        "        self.model = model\n",
        "        self.criterion = criterion  #the loss function\n",
        "        self.optimizer = optimizer  #the optimizer\n",
        "        self.train_loader = train_loader  #the train loader\n",
        "        self.val_loader = val_loader  #the valid loader\n",
        "\n",
        "    #the function to train the model in many epochs\n",
        "    def fit(self, num_epochs):\n",
        "        self.num_batches = len(self.train_loader)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "            train_loss, train_accuracy = self.train_one_epoch()\n",
        "            val_loss, val_accuracy = self.validate_one_epoch()\n",
        "            print(\n",
        "                f'{self.num_batches}/{self.num_batches} - train_loss: {train_loss:.4f} - train_accuracy: {train_accuracy*100:.4f}% \\\n",
        "                - val_loss: {val_loss:.4f} - val_accuracy: {val_accuracy*100:.4f}%')\n",
        "\n",
        "    #train in one epoch, return the train_acc, train_loss\n",
        "    def train_one_epoch(self):\n",
        "        self.model.train()\n",
        "        running_loss, correct, total = 0.0, 0, 0\n",
        "        for i, data in enumerate(self.train_loader):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(inputs)\n",
        "            loss = self.criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        train_accuracy = correct / total\n",
        "        train_loss = running_loss / self.num_batches\n",
        "        return train_loss, train_accuracy\n",
        "\n",
        "    #evaluate on a loader and return the loss and accuracy\n",
        "    def evaluate(self, loader):\n",
        "        self.model.eval()\n",
        "        loss, correct, total = 0.0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for data in loader:\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = correct / total\n",
        "        loss = loss / len(self.val_loader)\n",
        "        return loss, accuracy\n",
        "\n",
        "    #return the val_acc, val_loss, be called at the end of each epoch\n",
        "    def validate_one_epoch(self):\n",
        "      val_loss, val_accuracy = self.evaluate(self.val_loader)\n",
        "      return val_loss, val_accuracy"
      ],
      "metadata": {
        "id": "yXlNQvGn7OEb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#0b486b\">Part 4: Transformer-based models for sequence modeling and neural embedding</font>\n",
        "\n",
        "<div style=\"text-align: right\"><font color=\"red; font-weight:bold\">[Total marks for this part: 30 marks]<span></div>"
      ],
      "metadata": {
        "id": "sPvLRNDfoSq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color=\"red\">**Question 4.1**</font>\n",
        "\n",
        "**Implement the multi-head attention module of the Transformer for the text classification problem. The provided code is from our tutorial. In this part, we only use the output of the Transformer encoder for the classification task. For further information on the Transformer model, refer to [this paper](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf).**\n",
        "\n",
        "<div style=\"text-align: right\"><font color=\"red; font-weight:bold\">[Total marks for this part: 10 marks]<span></div>\n"
      ],
      "metadata": {
        "id": "QOoskR7Ko6Iv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the code of `MultiHeadSelfAttention`, `PositionWiseFeedForward`, `PositionalEncoding`, and `EncoderLayer`."
      ],
      "metadata": {
        "id": "LUnK0WBspLDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        # Ensure that the model dimension (d_model) is divisible by the number of heads\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        # Initialize dimensions\n",
        "        self.d_model = d_model # Model's dimension\n",
        "        self.num_heads = num_heads # Number of attention heads\n",
        "        self.d_k = d_model // num_heads # Dimension of each head's key, query, and value\n",
        "\n",
        "        # Linear layers for transforming inputs\n",
        "        self.W_q = nn.Linear(d_model, d_model) # Query transformation\n",
        "        self.W_k = nn.Linear(d_model, d_model) # Key transformation\n",
        "        self.W_v = nn.Linear(d_model, d_model) # Value transformation\n",
        "        self.W_o = nn.Linear(d_model, d_model) # Output transformation\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V):\n",
        "        # Calculate attention scores\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "\n",
        "        # Apply mask if provided (useful for preventing attention to certain parts like padding)\n",
        "        #if mask is not None:\n",
        "            #attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        # Softmax is applied to obtain attention probabilities\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "\n",
        "        # Multiply by values to obtain the final output\n",
        "        output = torch.matmul(attn_probs, V)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        # Reshape the input to have num_heads for multi-head attention\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        # Combine the multiple heads back to original shape\n",
        "        batch_size, _, seq_length, d_k = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
        "\n",
        "    def forward(self, Q, K, V):\n",
        "        # Apply linear transformations and split heads\n",
        "        Q = self.split_heads(self.W_q(Q))\n",
        "        K = self.split_heads(self.W_k(K))\n",
        "        V = self.split_heads(self.W_v(V))\n",
        "\n",
        "        # Perform scaled dot-product attention\n",
        "        attn_output = self.scaled_dot_product_attention(Q, K, V)\n",
        "\n",
        "        # Combine heads and apply output transformation\n",
        "        output = self.W_o(self.combine_heads(attn_output))\n",
        "        return output"
      ],
      "metadata": {
        "id": "PERuLdjTZpAl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionWiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PositionWiseFeedForward, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.relu(self.fc1(x)))"
      ],
      "metadata": {
        "id": "J4MZuO59pR0T"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_seq_length):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        pe = torch.zeros(max_seq_length, d_model)\n",
        "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]"
      ],
      "metadata": {
        "id": "qq15ROA9pV3N"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_output = self.self_attn(x, x, x)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "        return x"
      ],
      "metadata": {
        "id": "HKaj3paKqTmG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your task is to develop `TransformerClassifier` in which we input the embedding with the shape `[batch_size, seq_len, embed_dim]` to some `EncoderLayer` (i.e., num_layers specifies the number of EncoderLayer) and then compute the average of all token embeddings (i.e., `[batch_size, seq_len, embed_dim]`) across the `seq_len`. Finally, on the top of this average embedding, we build up a linear layer for making predictions."
      ],
      "metadata": {
        "id": "pI9I1Gl1ptq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerClassifier(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, num_layers, dropout_rate=0.2, data_manager = None):\n",
        "        super(TransformerClassifier, self).__init__()\n",
        "        self.vocab_size = data_manager.vocab_size\n",
        "        self.num_classes = data_manager.num_classes\n",
        "        self.embed_dim = embed_dim\n",
        "        self.max_seq_len = data_manager.max_seq_len\n",
        "        self.num_heads = num_heads\n",
        "        self.ff_dim = ff_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "    def build(self):\n",
        "\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embed_dim)\n",
        "        self.positional_encoding = PositionalEncoding(self.embed_dim, self.max_seq_len)\n",
        "\n",
        "        self.encoder_layers = nn.ModuleList()\n",
        "        for _ in range(self.num_layers):\n",
        "            self.encoder_layers.append(EncoderLayer(self.embed_dim, self.num_heads, self.ff_dim, self.dropout_rate))\n",
        "\n",
        "\n",
        "        self.fc = nn.Linear(self.embed_dim, self.num_classes)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.positional_encoding(x)\n",
        "        for layer in self.encoder_layers:\n",
        "            x = layer(x)\n",
        "        x = torch.mean(x, dim=1)\n",
        "\n",
        "        return self.fc(x)\n"
      ],
      "metadata": {
        "id": "VwzVfN2dpY_p"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = TransformerClassifier(embed_dim=512, num_heads=8, ff_dim=2048, num_layers=12, dropout_rate=0.1, data_manager= dm)\n",
        "transformer.build()\n",
        "transformer = transformer.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=1e-4, betas=(0.9, 0.98), eps=1e-9)\n",
        "trainer = BaseTrainer(model= transformer, criterion=criterion, optimizer=optimizer, train_loader=dm.train_loader, val_loader=dm.valid_loader)\n",
        "trainer.fit(num_epochs=30)"
      ],
      "metadata": {
        "id": "V4sjIOzQrn3b",
        "outputId": "8375089f-d41e-4611-ed67-3cd131dcc637",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "26/26 - train_loss: 1.8211 - train_accuracy: 22.0487%                 - val_loss: 0.8290 - val_accuracy: 18.1818%\n",
            "Epoch 2/30\n",
            "26/26 - train_loss: 1.7097 - train_accuracy: 21.9238%                 - val_loss: 0.7756 - val_accuracy: 18.6869%\n",
            "Epoch 3/30\n",
            "26/26 - train_loss: 1.3802 - train_accuracy: 41.6615%                 - val_loss: 0.7204 - val_accuracy: 35.8586%\n",
            "Epoch 4/30\n",
            "26/26 - train_loss: 1.2194 - train_accuracy: 42.9107%                 - val_loss: 0.7695 - val_accuracy: 44.4444%\n",
            "Epoch 5/30\n",
            "26/26 - train_loss: 1.1325 - train_accuracy: 45.5965%                 - val_loss: 0.5724 - val_accuracy: 53.5354%\n",
            "Epoch 6/30\n",
            "26/26 - train_loss: 0.8051 - train_accuracy: 65.8963%                 - val_loss: 0.1618 - val_accuracy: 86.3636%\n",
            "Epoch 7/30\n",
            "26/26 - train_loss: 0.2387 - train_accuracy: 91.6302%                 - val_loss: 0.0457 - val_accuracy: 91.9192%\n",
            "Epoch 8/30\n",
            "26/26 - train_loss: 0.1656 - train_accuracy: 93.5665%                 - val_loss: 0.0235 - val_accuracy: 92.9293%\n",
            "Epoch 9/30\n",
            "26/26 - train_loss: 0.1292 - train_accuracy: 95.3779%                 - val_loss: 0.0041 - val_accuracy: 95.9596%\n",
            "Epoch 10/30\n",
            "26/26 - train_loss: 0.0699 - train_accuracy: 97.3766%                 - val_loss: 0.0041 - val_accuracy: 93.9394%\n",
            "Epoch 11/30\n",
            "26/26 - train_loss: 0.0879 - train_accuracy: 96.6271%                 - val_loss: 0.0007 - val_accuracy: 94.9495%\n",
            "Epoch 12/30\n",
            "26/26 - train_loss: 0.0718 - train_accuracy: 97.3142%                 - val_loss: 0.0005 - val_accuracy: 94.9495%\n",
            "Epoch 13/30\n",
            "26/26 - train_loss: 0.0509 - train_accuracy: 98.3760%                 - val_loss: 0.0005 - val_accuracy: 95.4545%\n",
            "Epoch 14/30\n",
            "26/26 - train_loss: 0.0440 - train_accuracy: 98.2511%                 - val_loss: 0.0052 - val_accuracy: 94.9495%\n",
            "Epoch 15/30\n",
            "26/26 - train_loss: 0.0314 - train_accuracy: 99.2505%                 - val_loss: 0.0005 - val_accuracy: 97.4747%\n",
            "Epoch 16/30\n",
            "26/26 - train_loss: 0.0325 - train_accuracy: 99.3129%                 - val_loss: 0.0027 - val_accuracy: 95.4545%\n",
            "Epoch 17/30\n",
            "26/26 - train_loss: 0.0240 - train_accuracy: 99.3754%                 - val_loss: 0.0006 - val_accuracy: 95.9596%\n",
            "Epoch 18/30\n",
            "26/26 - train_loss: 0.0545 - train_accuracy: 98.6259%                 - val_loss: 0.0058 - val_accuracy: 96.4646%\n",
            "Epoch 19/30\n",
            "26/26 - train_loss: 0.0547 - train_accuracy: 98.6883%                 - val_loss: 0.0003 - val_accuracy: 96.4646%\n",
            "Epoch 20/30\n",
            "26/26 - train_loss: 0.0333 - train_accuracy: 99.5628%                 - val_loss: 0.0016 - val_accuracy: 96.4646%\n",
            "Epoch 21/30\n",
            "26/26 - train_loss: 0.0520 - train_accuracy: 99.5628%                 - val_loss: 0.0002 - val_accuracy: 96.4646%\n",
            "Epoch 22/30\n",
            "26/26 - train_loss: 0.1321 - train_accuracy: 97.6265%                 - val_loss: 0.0063 - val_accuracy: 95.4545%\n",
            "Epoch 23/30\n",
            "26/26 - train_loss: 0.0081 - train_accuracy: 99.8751%                 - val_loss: 0.0004 - val_accuracy: 96.4646%\n",
            "Epoch 24/30\n",
            "26/26 - train_loss: 0.0036 - train_accuracy: 99.9375%                 - val_loss: 0.0001 - val_accuracy: 97.4747%\n",
            "Epoch 25/30\n",
            "26/26 - train_loss: 0.0005 - train_accuracy: 100.0000%                 - val_loss: 0.0001 - val_accuracy: 96.9697%\n",
            "Epoch 26/30\n",
            "26/26 - train_loss: 0.0003 - train_accuracy: 100.0000%                 - val_loss: 0.0000 - val_accuracy: 96.9697%\n",
            "Epoch 27/30\n",
            "26/26 - train_loss: 0.0002 - train_accuracy: 100.0000%                 - val_loss: 0.0000 - val_accuracy: 96.4646%\n",
            "Epoch 28/30\n",
            "26/26 - train_loss: 0.0001 - train_accuracy: 100.0000%                 - val_loss: 0.0000 - val_accuracy: 96.4646%\n",
            "Epoch 29/30\n",
            "26/26 - train_loss: 0.0001 - train_accuracy: 100.0000%                 - val_loss: 0.0000 - val_accuracy: 96.4646%\n",
            "Epoch 30/30\n",
            "26/26 - train_loss: 0.0001 - train_accuracy: 100.0000%                 - val_loss: 0.0000 - val_accuracy: 96.4646%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color=\"red\">**Question 4.2**</font>\n",
        "**Prefix prompt-tuning with Transformers: You need to implement the prefix prompt-tuning with Transformers. Basically, we base on a pre-trained Transformer, add prefix prompts, and do fine-tuning for a target dataset.**\n",
        "\n",
        "<div style=\"text-align: right\"><font color=\"red; font-weight:bold\">[Total marks for this part: 10 marks]<span></div>"
      ],
      "metadata": {
        "id": "aMbhi0_d0NL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To implement prefix prompt-tuning with pretrained Transformers, we first need to create the Bert dataset."
      ],
      "metadata": {
        "id": "UyecWD190TP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer, AdamW\n",
        "from datasets import Dataset\n",
        "\n",
        "model_name = \"bert-base-uncased\"  # BERT or any similar model\n",
        "\n",
        "# Tokenize input and prepare model inputs\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "dataset = Dataset.from_dict({\"text\": dm.str_questions, \"label\": dm.numeral_labels})\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length= 36)\n",
        "\n",
        "dataset = dataset.map(tokenize_function, batched=True)\n",
        "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "eccdad491e284a74ba6005a6fd511128",
            "b844ce6ecb88459990d6c6fe5445812b",
            "ccdea0e274814da4ac9d6c9f5b05f541",
            "a6b7e08deab548c5944bb69f9cf288e8",
            "505dec7196654dc290ce103b57fb5d9b",
            "b395be123db449a19b8ebd416962729d",
            "b8a6801026a74641a6904ac24fac4ca3",
            "812ff4a6481e45dc9cb6ac192eda9867",
            "b6e2cf5cf6fd4cb288b817a9cd25fb95",
            "aa060231ea8d401dbfd132d4f3fa0040",
            "c53ec3a0072f48278cee76016a921992"
          ]
        },
        "id": "mq3PiV2UrueO",
        "outputId": "59e7fe28-22b6-4592-a94d-7f1ccc629e58"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eccdad491e284a74ba6005a6fd511128"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "    num_rows: 2000\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function splits the BERT dataset `dataset` into three BERT datasets for training, valid, and testing."
      ],
      "metadata": {
        "id": "ASKOrO5n1ckY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_valid_test_split(dataset, train_ratio=0.8, test_ratio = 0.1):\n",
        "    num_sentences = len(dataset)\n",
        "    train_size = int(num_sentences*train_ratio) +1\n",
        "    test_size = int(num_sentences*test_ratio) +1\n",
        "    valid_size = num_sentences - (train_size + test_size)\n",
        "    train_set = dataset[:train_size]\n",
        "    train_set = Dataset.from_dict(train_set)\n",
        "    train_set.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "    test_set = dataset[-test_size:]\n",
        "    test_set = Dataset.from_dict(test_set)\n",
        "    test_set.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "    valid_set = dataset[train_size:-test_size]\n",
        "    valid_set = Dataset.from_dict(valid_set)\n",
        "    valid_set.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n",
        "    valid_loader = DataLoader(valid_set, batch_size=64, shuffle=False)\n",
        "    return train_loader, test_loader, valid_loader\n"
      ],
      "metadata": {
        "id": "UDgfnCV70gzG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader, valid_loader = train_valid_test_split(dataset)"
      ],
      "metadata": {
        "id": "s_sEtXml1lT7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You need to implement the class `PrefixTuningForClassification` for the prefix prompt fine-tuning. We first load a pre-trained BERT model specified by `model_name`. The parameter `prefix_length` specifies the length of the prefix prompts we add to the pre-trained BERT model. Specifically, given the input batch `[batch_size, seq_len]`, we input to the embedding layer of the pre-trained BERT model to obtain `[batch_size, seq_len, embed_size]`. We create the prefix prompts $P$ of the size `[prefix_length, embed_size]` and concatenate to the embeddings from the pre-trained BERT to obtain `[batch_size, seq_len + prefix_length, embed_size]`. This concatenation tensor will then be fed to the encoder layers of the pre-trained BERT layer to obtain the last `[batch_size, seq_len + prefix_length, embed_size]`."
      ],
      "metadata": {
        "id": "S3jHATGX2hn4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then take mean across the seq_len to obtain `[batch_size, embed_size]` on which we can build up a linear layer for making predictions. Please note that **the parameters to tune include the prefix prompts $P$** and **the output linear layer**, and you should freeze the parameters of the BERT pre-trained model. Moreover, your code should cover the edge case when `prefix_length=None`. In this case, we do not insert any prefix prompts and we only do fine-tuning for the output linear layer on top.  "
      ],
      "metadata": {
        "id": "NXFogDf1jVD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PrefixTuningForClassification(nn.Module):\n",
        "    def __init__(self, model_name, prefix_length=None, data_manager = None):\n",
        "        super(PrefixTuningForClassification, self).__init__()\n",
        "\n",
        "        # Load the pretrained transformer model (BERT-like model)\n",
        "        self.model = AutoModel.from_pretrained(model_name).to(device)\n",
        "        self.hidden_size =  self.model.config.hidden_size\n",
        "        self.prefix_length = prefix_length\n",
        "        self.num_classes = data_manager.num_classes\n",
        "        self.build()\n",
        "\n",
        "    def build(self):\n",
        "        self.prefix_embeddings = torch.empty(self.prefix_length, self.hidden_size).to(device)\n",
        "        torch.nn.init.xavier_uniform_(self.prefix_embeddings)\n",
        "        self.prefix_embeddings.requires_grad = True\n",
        "\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.classifier = nn.Linear(self.hidden_size, self.num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        embeddings = self.model.embeddings(input_ids)\n",
        "        prefix_embeddings_expanded = self.prefix_embeddings.unsqueeze(0).expand(embeddings.shape[0], -1, -1)\n",
        "        embeddings = torch.cat((prefix_embeddings_expanded, embeddings), dim=1)\n",
        "        batch_size, seq_len = input_ids.shape\n",
        "        extended_attention_mask = torch.cat(\n",
        "            (torch.ones(batch_size, self.prefix_length, device=attention_mask.device), attention_mask),\n",
        "            dim=1\n",
        "        )\n",
        "        extended_attention_mask = self.model.get_extended_attention_mask(extended_attention_mask, (batch_size, seq_len + self.prefix_length), attention_mask.device)\n",
        "        x = self.model.encoder(embeddings, attention_mask=extended_attention_mask).last_hidden_state\n",
        "        x = torch.mean(x, dim=1)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "bZtGBqQV16Kj"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "m7w7qOdq602o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use the following `FineTunedBaseTrainer` to train the prompt fine-tuning models."
      ],
      "metadata": {
        "id": "RtYVNYXi24Os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FineTunedBaseTrainer:\n",
        "    def __init__(self, model, criterion, optimizer, train_loader, val_loader):\n",
        "        self.model = model\n",
        "        self.criterion = criterion  #the loss function\n",
        "        self.optimizer = optimizer  #the optimizer\n",
        "        self.train_loader = train_loader  #the train loader\n",
        "        self.val_loader = val_loader  #the valid loader\n",
        "\n",
        "    #the function to train the model in many epochs\n",
        "    def fit(self, num_epochs):\n",
        "        self.num_batches = len(self.train_loader)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "            train_loss, train_accuracy = self.train_one_epoch()\n",
        "            val_loss, val_accuracy = self.validate_one_epoch()\n",
        "            print(\n",
        "                f'{self.num_batches}/{self.num_batches} - train_loss: {train_loss:.4f} - train_accuracy: {train_accuracy*100:.4f}% \\\n",
        "                - val_loss: {val_loss:.4f} - val_accuracy: {val_accuracy*100:.4f}%')\n",
        "\n",
        "    #train in one epoch, return the train_acc, train_loss\n",
        "    def train_one_epoch(self):\n",
        "        self.model.train()\n",
        "        running_loss, correct, total = 0.0, 0, 0\n",
        "        for batch in self.train_loader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(input_ids= input_ids, attention_mask= attention_mask)\n",
        "            loss = self.criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        train_accuracy = correct / total\n",
        "        train_loss = running_loss / self.num_batches\n",
        "        return train_loss, train_accuracy\n",
        "\n",
        "    #evaluate on a loader and return the loss and accuracy\n",
        "    def evaluate(self, loader):\n",
        "        self.model.eval()\n",
        "        loss, correct, total = 0.0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for batch in loader:\n",
        "                input_ids = batch[\"input_ids\"].to(device)\n",
        "                labels = batch[\"label\"].to(device)\n",
        "                attention_mask = batch[\"attention_mask\"].to(device)\n",
        "                outputs = self.model(input_ids= input_ids, attention_mask= attention_mask)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = correct / total\n",
        "        loss = loss / len(self.val_loader)\n",
        "        return loss, accuracy\n",
        "\n",
        "    #return the val_acc, val_loss, be called at the end of each epoch\n",
        "    def validate_one_epoch(self):\n",
        "      val_loss, val_accuracy = self.evaluate(self.val_loader)\n",
        "      return val_loss, val_accuracy"
      ],
      "metadata": {
        "id": "NmRkMqYB24tv"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We declare and train the prefix-prompt tuning model. In addition, you need to be patient with this model because it might converge slowly with many epochs."
      ],
      "metadata": {
        "id": "4KQhBHPe20zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefix_tuning_model = PrefixTuningForClassification(model_name = \"bert-base-uncased\", prefix_length = 5, data_manager = dm).to(device)"
      ],
      "metadata": {
        "id": "qLowEOeg3HWW"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if prefix_tuning_model.prefix_length is not None:\n",
        "  optimizer = torch.optim.Adam(list(prefix_tuning_model.classifier.parameters()) + [prefix_tuning_model.prefix_embeddings], lr=5e-5)\n",
        "else:\n",
        "  optimizer = torch.optim.Adam(prefix_tuning_model.classifier.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "trainer = FineTunedBaseTrainer(model= prefix_tuning_model, criterion=criterion, optimizer=optimizer, train_loader=train_loader, val_loader=valid_loader)\n",
        "trainer.fit(num_epochs=100)"
      ],
      "metadata": {
        "id": "UYMDOjWW3UVk",
        "outputId": "648b9670-0b75-4339-94ed-69483d7cafc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:1126: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 - train_loss: 1.8039 - train_accuracy: 19.7377%                 - val_loss: 0.8695 - val_accuracy: 28.7879%\n",
            "Epoch 2/100\n",
            "26/26 - train_loss: 1.7616 - train_accuracy: 27.1705%                 - val_loss: 0.8537 - val_accuracy: 32.8283%\n",
            "Epoch 3/100\n",
            "26/26 - train_loss: 1.7272 - train_accuracy: 31.8551%                 - val_loss: 0.8403 - val_accuracy: 34.8485%\n",
            "Epoch 4/100\n",
            "26/26 - train_loss: 1.6892 - train_accuracy: 34.9157%                 - val_loss: 0.8292 - val_accuracy: 35.8586%\n",
            "Epoch 5/100\n",
            "26/26 - train_loss: 1.6667 - train_accuracy: 37.6640%                 - val_loss: 0.8203 - val_accuracy: 39.3939%\n",
            "Epoch 6/100\n",
            "26/26 - train_loss: 1.6427 - train_accuracy: 39.9126%                 - val_loss: 0.8115 - val_accuracy: 45.4545%\n",
            "Epoch 7/100\n",
            "26/26 - train_loss: 1.6308 - train_accuracy: 42.2861%                 - val_loss: 0.8033 - val_accuracy: 46.4646%\n",
            "Epoch 8/100\n",
            "26/26 - train_loss: 1.6088 - train_accuracy: 43.8476%                 - val_loss: 0.7950 - val_accuracy: 48.9899%\n",
            "Epoch 9/100\n",
            "26/26 - train_loss: 1.5888 - train_accuracy: 46.7833%                 - val_loss: 0.7848 - val_accuracy: 50.0000%\n",
            "Epoch 10/100\n",
            "26/26 - train_loss: 1.5674 - train_accuracy: 46.8457%                 - val_loss: 0.7778 - val_accuracy: 53.0303%\n",
            "Epoch 11/100\n",
            "26/26 - train_loss: 1.5569 - train_accuracy: 47.5953%                 - val_loss: 0.7731 - val_accuracy: 52.0202%\n",
            "Epoch 12/100\n",
            "26/26 - train_loss: 1.5358 - train_accuracy: 48.4697%                 - val_loss: 0.7673 - val_accuracy: 52.5253%\n",
            "Epoch 13/100\n",
            "26/26 - train_loss: 1.5307 - train_accuracy: 48.0325%                 - val_loss: 0.7536 - val_accuracy: 54.5455%\n",
            "Epoch 14/100\n",
            "26/26 - train_loss: 1.5001 - train_accuracy: 49.5315%                 - val_loss: 0.7456 - val_accuracy: 55.5556%\n",
            "Epoch 15/100\n",
            "26/26 - train_loss: 1.4895 - train_accuracy: 50.7808%                 - val_loss: 0.7361 - val_accuracy: 55.0505%\n",
            "Epoch 16/100\n",
            "26/26 - train_loss: 1.4768 - train_accuracy: 51.7801%                 - val_loss: 0.7268 - val_accuracy: 55.5556%\n",
            "Epoch 17/100\n",
            "26/26 - train_loss: 1.4884 - train_accuracy: 50.5309%                 - val_loss: 0.7179 - val_accuracy: 56.5657%\n",
            "Epoch 18/100\n",
            "26/26 - train_loss: 1.4483 - train_accuracy: 53.2792%                 - val_loss: 0.7123 - val_accuracy: 58.0808%\n",
            "Epoch 19/100\n",
            "26/26 - train_loss: 1.4624 - train_accuracy: 53.6540%                 - val_loss: 0.7056 - val_accuracy: 58.0808%\n",
            "Epoch 20/100\n",
            "26/26 - train_loss: 1.4424 - train_accuracy: 55.2155%                 - val_loss: 0.7053 - val_accuracy: 57.0707%\n",
            "Epoch 21/100\n",
            "26/26 - train_loss: 1.4224 - train_accuracy: 56.4647%                 - val_loss: 0.7014 - val_accuracy: 59.0909%\n",
            "Epoch 22/100\n",
            "26/26 - train_loss: 1.4202 - train_accuracy: 56.9019%                 - val_loss: 0.6993 - val_accuracy: 59.5960%\n",
            "Epoch 23/100\n",
            "26/26 - train_loss: 1.3951 - train_accuracy: 58.9631%                 - val_loss: 0.6930 - val_accuracy: 62.6263%\n",
            "Epoch 24/100\n",
            "26/26 - train_loss: 1.3973 - train_accuracy: 59.3379%                 - val_loss: 0.6902 - val_accuracy: 61.6162%\n",
            "Epoch 25/100\n",
            "26/26 - train_loss: 1.3750 - train_accuracy: 59.0881%                 - val_loss: 0.6865 - val_accuracy: 61.1111%\n",
            "Epoch 26/100\n",
            "26/26 - train_loss: 1.3940 - train_accuracy: 60.5871%                 - val_loss: 0.6759 - val_accuracy: 61.1111%\n",
            "Epoch 27/100\n",
            "26/26 - train_loss: 1.3797 - train_accuracy: 61.4616%                 - val_loss: 0.6687 - val_accuracy: 63.6364%\n",
            "Epoch 28/100\n",
            "26/26 - train_loss: 1.3342 - train_accuracy: 63.6477%                 - val_loss: 0.6606 - val_accuracy: 66.1616%\n",
            "Epoch 29/100\n",
            "26/26 - train_loss: 1.3601 - train_accuracy: 63.0231%                 - val_loss: 0.6518 - val_accuracy: 66.1616%\n",
            "Epoch 30/100\n",
            "26/26 - train_loss: 1.3401 - train_accuracy: 65.2717%                 - val_loss: 0.6452 - val_accuracy: 67.6768%\n",
            "Epoch 31/100\n",
            "26/26 - train_loss: 1.3466 - train_accuracy: 65.1468%                 - val_loss: 0.6399 - val_accuracy: 67.6768%\n",
            "Epoch 32/100\n",
            "26/26 - train_loss: 1.3198 - train_accuracy: 66.1462%                 - val_loss: 0.6337 - val_accuracy: 70.2020%\n",
            "Epoch 33/100\n",
            "26/26 - train_loss: 1.2933 - train_accuracy: 66.3335%                 - val_loss: 0.6301 - val_accuracy: 68.1818%\n",
            "Epoch 34/100\n",
            "26/26 - train_loss: 1.2987 - train_accuracy: 66.3960%                 - val_loss: 0.6206 - val_accuracy: 68.6869%\n",
            "Epoch 35/100\n",
            "26/26 - train_loss: 1.2873 - train_accuracy: 66.1462%                 - val_loss: 0.6136 - val_accuracy: 68.6869%\n",
            "Epoch 36/100\n",
            "26/26 - train_loss: 1.2705 - train_accuracy: 68.1449%                 - val_loss: 0.6109 - val_accuracy: 71.2121%\n",
            "Epoch 37/100\n",
            "26/26 - train_loss: 1.2669 - train_accuracy: 67.5828%                 - val_loss: 0.6101 - val_accuracy: 71.2121%\n",
            "Epoch 38/100\n",
            "26/26 - train_loss: 1.2331 - train_accuracy: 67.8326%                 - val_loss: 0.6059 - val_accuracy: 69.6970%\n",
            "Epoch 39/100\n",
            "26/26 - train_loss: 1.2622 - train_accuracy: 68.5821%                 - val_loss: 0.5978 - val_accuracy: 70.7071%\n",
            "Epoch 40/100\n",
            "26/26 - train_loss: 1.2397 - train_accuracy: 68.8944%                 - val_loss: 0.5932 - val_accuracy: 71.2121%\n",
            "Epoch 41/100\n",
            "26/26 - train_loss: 1.2229 - train_accuracy: 70.3310%                 - val_loss: 0.5892 - val_accuracy: 72.2222%\n",
            "Epoch 42/100\n",
            "26/26 - train_loss: 1.2049 - train_accuracy: 70.0187%                 - val_loss: 0.5881 - val_accuracy: 72.2222%\n",
            "Epoch 43/100\n",
            "26/26 - train_loss: 1.2076 - train_accuracy: 70.0187%                 - val_loss: 0.5861 - val_accuracy: 71.7172%\n",
            "Epoch 44/100\n",
            "26/26 - train_loss: 1.1942 - train_accuracy: 69.3317%                 - val_loss: 0.5790 - val_accuracy: 72.2222%\n",
            "Epoch 45/100\n",
            "26/26 - train_loss: 1.1865 - train_accuracy: 72.1424%                 - val_loss: 0.5719 - val_accuracy: 73.7374%\n",
            "Epoch 46/100\n",
            "26/26 - train_loss: 1.1734 - train_accuracy: 70.0187%                 - val_loss: 0.5666 - val_accuracy: 73.7374%\n",
            "Epoch 47/100\n",
            "26/26 - train_loss: 1.1543 - train_accuracy: 70.0187%                 - val_loss: 0.5608 - val_accuracy: 74.2424%\n",
            "Epoch 48/100\n",
            "26/26 - train_loss: 1.1650 - train_accuracy: 70.9557%                 - val_loss: 0.5499 - val_accuracy: 74.7475%\n",
            "Epoch 49/100\n",
            "26/26 - train_loss: 1.1344 - train_accuracy: 70.8307%                 - val_loss: 0.5446 - val_accuracy: 75.2525%\n",
            "Epoch 50/100\n",
            "26/26 - train_loss: 1.1497 - train_accuracy: 70.6433%                 - val_loss: 0.5375 - val_accuracy: 75.2525%\n",
            "Epoch 51/100\n",
            "26/26 - train_loss: 1.1241 - train_accuracy: 71.5178%                 - val_loss: 0.5375 - val_accuracy: 75.7576%\n",
            "Epoch 52/100\n",
            "26/26 - train_loss: 1.1569 - train_accuracy: 71.5178%                 - val_loss: 0.5315 - val_accuracy: 75.7576%\n",
            "Epoch 53/100\n",
            "26/26 - train_loss: 1.1201 - train_accuracy: 73.2042%                 - val_loss: 0.5240 - val_accuracy: 77.2727%\n",
            "Epoch 54/100\n",
            "26/26 - train_loss: 1.0990 - train_accuracy: 73.3292%                 - val_loss: 0.5161 - val_accuracy: 76.7677%\n",
            "Epoch 55/100\n",
            "26/26 - train_loss: 1.1082 - train_accuracy: 74.0787%                 - val_loss: 0.5091 - val_accuracy: 77.2727%\n",
            "Epoch 56/100\n",
            "26/26 - train_loss: 1.0985 - train_accuracy: 73.2667%                 - val_loss: 0.5053 - val_accuracy: 76.7677%\n",
            "Epoch 57/100\n",
            "26/26 - train_loss: 1.0916 - train_accuracy: 74.8282%                 - val_loss: 0.4998 - val_accuracy: 77.7778%\n",
            "Epoch 58/100\n",
            "26/26 - train_loss: 1.0831 - train_accuracy: 74.4535%                 - val_loss: 0.4903 - val_accuracy: 77.2727%\n",
            "Epoch 59/100\n",
            "26/26 - train_loss: 1.0522 - train_accuracy: 74.0162%                 - val_loss: 0.4893 - val_accuracy: 77.2727%\n",
            "Epoch 60/100\n",
            "26/26 - train_loss: 1.0596 - train_accuracy: 74.6408%                 - val_loss: 0.4828 - val_accuracy: 76.7677%\n",
            "Epoch 61/100\n",
            "26/26 - train_loss: 1.0650 - train_accuracy: 75.2030%                 - val_loss: 0.4837 - val_accuracy: 77.2727%\n",
            "Epoch 62/100\n",
            "26/26 - train_loss: 1.0397 - train_accuracy: 75.5153%                 - val_loss: 0.4809 - val_accuracy: 77.2727%\n",
            "Epoch 63/100\n",
            "26/26 - train_loss: 1.0528 - train_accuracy: 75.8276%                 - val_loss: 0.4732 - val_accuracy: 78.7879%\n",
            "Epoch 64/100\n",
            "26/26 - train_loss: 1.0238 - train_accuracy: 77.2642%                 - val_loss: 0.4682 - val_accuracy: 79.2929%\n",
            "Epoch 65/100\n",
            "26/26 - train_loss: 1.0266 - train_accuracy: 75.7651%                 - val_loss: 0.4658 - val_accuracy: 78.7879%\n",
            "Epoch 66/100\n",
            "26/26 - train_loss: 1.0266 - train_accuracy: 76.9519%                 - val_loss: 0.4613 - val_accuracy: 78.2828%\n",
            "Epoch 67/100\n",
            "26/26 - train_loss: 1.0086 - train_accuracy: 76.5147%                 - val_loss: 0.4567 - val_accuracy: 79.7980%\n",
            "Epoch 68/100\n",
            "26/26 - train_loss: 0.9872 - train_accuracy: 76.2648%                 - val_loss: 0.4502 - val_accuracy: 79.2929%\n",
            "Epoch 69/100\n",
            "26/26 - train_loss: 1.0036 - train_accuracy: 76.4522%                 - val_loss: 0.4398 - val_accuracy: 79.2929%\n",
            "Epoch 70/100\n",
            "26/26 - train_loss: 0.9777 - train_accuracy: 77.2642%                 - val_loss: 0.4343 - val_accuracy: 80.3030%\n",
            "Epoch 71/100\n",
            "26/26 - train_loss: 0.9674 - train_accuracy: 76.2648%                 - val_loss: 0.4293 - val_accuracy: 79.2929%\n",
            "Epoch 72/100\n",
            "26/26 - train_loss: 0.9764 - train_accuracy: 77.2017%                 - val_loss: 0.4242 - val_accuracy: 81.3131%\n",
            "Epoch 73/100\n",
            "26/26 - train_loss: 0.9754 - train_accuracy: 77.8888%                 - val_loss: 0.4208 - val_accuracy: 80.3030%\n",
            "Epoch 74/100\n",
            "26/26 - train_loss: 0.9231 - train_accuracy: 77.8264%                 - val_loss: 0.4142 - val_accuracy: 79.7980%\n",
            "Epoch 75/100\n",
            "26/26 - train_loss: 0.9472 - train_accuracy: 77.5141%                 - val_loss: 0.4122 - val_accuracy: 80.8081%\n",
            "Epoch 76/100\n",
            "26/26 - train_loss: 0.9245 - train_accuracy: 78.0137%                 - val_loss: 0.4090 - val_accuracy: 80.8081%\n",
            "Epoch 77/100\n",
            "26/26 - train_loss: 0.9415 - train_accuracy: 77.5141%                 - val_loss: 0.4040 - val_accuracy: 80.3030%\n",
            "Epoch 78/100\n",
            "26/26 - train_loss: 0.9257 - train_accuracy: 78.6384%                 - val_loss: 0.4011 - val_accuracy: 80.8081%\n",
            "Epoch 79/100\n",
            "26/26 - train_loss: 0.9101 - train_accuracy: 77.0144%                 - val_loss: 0.3972 - val_accuracy: 81.8182%\n",
            "Epoch 80/100\n",
            "26/26 - train_loss: 0.9163 - train_accuracy: 78.0762%                 - val_loss: 0.3918 - val_accuracy: 81.8182%\n",
            "Epoch 81/100\n",
            "26/26 - train_loss: 0.9105 - train_accuracy: 77.8264%                 - val_loss: 0.3891 - val_accuracy: 82.8283%\n",
            "Epoch 82/100\n",
            "26/26 - train_loss: 0.9037 - train_accuracy: 79.3879%                 - val_loss: 0.3891 - val_accuracy: 82.8283%\n",
            "Epoch 83/100\n",
            "26/26 - train_loss: 0.9275 - train_accuracy: 79.0131%                 - val_loss: 0.3842 - val_accuracy: 82.3232%\n",
            "Epoch 84/100\n",
            "26/26 - train_loss: 0.8787 - train_accuracy: 78.5134%                 - val_loss: 0.3782 - val_accuracy: 82.8283%\n",
            "Epoch 85/100\n",
            "26/26 - train_loss: 0.8650 - train_accuracy: 79.7002%                 - val_loss: 0.3790 - val_accuracy: 82.3232%\n",
            "Epoch 86/100\n",
            "26/26 - train_loss: 0.8616 - train_accuracy: 80.0125%                 - val_loss: 0.3781 - val_accuracy: 82.3232%\n",
            "Epoch 87/100\n",
            "26/26 - train_loss: 0.8573 - train_accuracy: 79.3254%                 - val_loss: 0.3731 - val_accuracy: 81.8182%\n",
            "Epoch 88/100\n",
            "26/26 - train_loss: 0.8355 - train_accuracy: 80.8245%                 - val_loss: 0.3694 - val_accuracy: 81.8182%\n",
            "Epoch 89/100\n",
            "26/26 - train_loss: 0.8282 - train_accuracy: 79.8876%                 - val_loss: 0.3638 - val_accuracy: 82.8283%\n",
            "Epoch 90/100\n",
            "26/26 - train_loss: 0.8483 - train_accuracy: 80.8245%                 - val_loss: 0.3621 - val_accuracy: 82.8283%\n",
            "Epoch 91/100\n",
            "26/26 - train_loss: 0.8219 - train_accuracy: 80.4497%                 - val_loss: 0.3593 - val_accuracy: 83.3333%\n",
            "Epoch 92/100\n",
            "26/26 - train_loss: 0.8200 - train_accuracy: 80.3248%                 - val_loss: 0.3551 - val_accuracy: 83.8384%\n",
            "Epoch 93/100\n",
            "26/26 - train_loss: 0.8342 - train_accuracy: 81.1368%                 - val_loss: 0.3523 - val_accuracy: 83.3333%\n",
            "Epoch 94/100\n",
            "26/26 - train_loss: 0.8054 - train_accuracy: 80.6371%                 - val_loss: 0.3525 - val_accuracy: 82.8283%\n",
            "Epoch 95/100\n",
            "26/26 - train_loss: 0.7935 - train_accuracy: 79.9500%                 - val_loss: 0.3475 - val_accuracy: 82.8283%\n",
            "Epoch 96/100\n",
            "26/26 - train_loss: 0.7918 - train_accuracy: 80.0750%                 - val_loss: 0.3451 - val_accuracy: 82.8283%\n",
            "Epoch 97/100\n",
            "26/26 - train_loss: 0.7895 - train_accuracy: 81.5740%                 - val_loss: 0.3403 - val_accuracy: 83.3333%\n",
            "Epoch 98/100\n",
            "26/26 - train_loss: 0.7850 - train_accuracy: 80.8245%                 - val_loss: 0.3397 - val_accuracy: 83.3333%\n",
            "Epoch 99/100\n",
            "26/26 - train_loss: 0.8293 - train_accuracy: 79.9500%                 - val_loss: 0.3383 - val_accuracy: 83.3333%\n",
            "Epoch 100/100\n",
            "26/26 - train_loss: 0.8363 - train_accuracy: 80.9494%                 - val_loss: 0.3347 - val_accuracy: 83.3333%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color=\"red\">**Question 4.3**</font>\n",
        "**For any models defined in the previous questions (of all parts), you are free to fine-tune hyperparameters, e.g., `optimizer`, `learning_rate`, `state_sizes`, such that you get a best model, i.e., the one with the highest accuracy on the test set. You will need to report (i) what is your best model,  (ii) its accuracy on the test set, and (iii) the values of its hyperparameters. Note that you must report your best model's accuracy with rounding to 4 decimal places, i.e., 0.xxxx. You will also need to upload your best model (or provide us with the link to download your best model). The assessment will be based on your best model's accuracy, with up to 9 marks available, specifically:**\n",
        "* The best accuracy $\\ge$ 0.97: 10 marks\n",
        "* 0.97 $>$ The best accuracy $\\ge$ 0.92: 7 marks\n",
        "* 0.92 $>$ The best accuracy $\\ge$ 0.85: 4 marks\n",
        "* The best accuracy $<$ 0.85: 0 mark\n",
        "\n",
        "**For this question, you can put below the code to train the best model. In this case, you need to show your code and the evidence of running regarding the best model. Moreover, if you save the best model, you need to provide the link to download the best model, the code to load the best model, and then evaluate on the test set.**\n",
        "<div style=\"text-align: right\"><font color=\"red\">[10 marks]</font></div>"
      ],
      "metadata": {
        "id": "xi6PnvdO-Glw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Give your answer here.\n",
        "\n",
        "(i) What is your best model?\n",
        "\n",
        "(ii) The accuracy of your best model on the test set\n",
        "\n",
        "(iii) The values of the hyperparameters of your best model\n",
        "\n",
        "(iv) The link to download your best model"
      ],
      "metadata": {
        "id": "EvM2pq3J-K0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefix_tuning_model = PrefixTuningForClassification(model_name = \"bert-large-uncased\", prefix_length = 20, data_manager = dm).to(device)\n",
        "optimizer = torch.optim.Adam(list(prefix_tuning_model.classifier.parameters()) + [prefix_tuning_model.prefix_embeddings], lr=4e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "trainer = FineTunedBaseTrainer(model= prefix_tuning_model, criterion=criterion, optimizer=optimizer, train_loader=train_loader, val_loader=valid_loader)\n",
        "trainer.fit(num_epochs=200)"
      ],
      "metadata": {
        "id": "l3NqVk5aF5vb",
        "outputId": "4a9e7a1d-ccef-488f-e05b-92a7b093f858",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:1126: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 - train_loss: 1.7613 - train_accuracy: 18.9257%                 - val_loss: 0.8587 - val_accuracy: 24.2424%\n",
            "Epoch 2/200\n",
            "26/26 - train_loss: 1.7170 - train_accuracy: 20.6746%                 - val_loss: 0.8412 - val_accuracy: 27.2727%\n",
            "Epoch 3/200\n",
            "26/26 - train_loss: 1.6870 - train_accuracy: 24.9844%                 - val_loss: 0.8317 - val_accuracy: 31.3131%\n",
            "Epoch 4/200\n",
            "26/26 - train_loss: 1.6792 - train_accuracy: 26.4210%                 - val_loss: 0.8245 - val_accuracy: 32.8283%\n",
            "Epoch 5/200\n",
            "26/26 - train_loss: 1.6623 - train_accuracy: 29.1068%                 - val_loss: 0.8176 - val_accuracy: 35.8586%\n",
            "Epoch 6/200\n",
            "26/26 - train_loss: 1.6366 - train_accuracy: 30.5434%                 - val_loss: 0.8098 - val_accuracy: 35.3535%\n",
            "Epoch 7/200\n",
            "26/26 - train_loss: 1.6309 - train_accuracy: 31.6052%                 - val_loss: 0.8066 - val_accuracy: 33.3333%\n",
            "Epoch 8/200\n",
            "26/26 - train_loss: 1.6162 - train_accuracy: 33.5415%                 - val_loss: 0.7995 - val_accuracy: 33.3333%\n",
            "Epoch 9/200\n",
            "26/26 - train_loss: 1.6053 - train_accuracy: 35.2280%                 - val_loss: 0.8085 - val_accuracy: 36.3636%\n",
            "Epoch 10/200\n",
            "26/26 - train_loss: 1.5959 - train_accuracy: 36.6646%                 - val_loss: 0.8023 - val_accuracy: 36.3636%\n",
            "Epoch 11/200\n",
            "26/26 - train_loss: 1.5838 - train_accuracy: 36.2898%                 - val_loss: 0.8017 - val_accuracy: 41.4141%\n",
            "Epoch 12/200\n",
            "26/26 - train_loss: 1.5789 - train_accuracy: 35.2904%                 - val_loss: 0.7918 - val_accuracy: 40.9091%\n",
            "Epoch 13/200\n",
            "26/26 - train_loss: 1.5807 - train_accuracy: 36.2274%                 - val_loss: 0.7793 - val_accuracy: 37.3737%\n",
            "Epoch 14/200\n",
            "26/26 - train_loss: 1.5741 - train_accuracy: 38.9756%                 - val_loss: 0.7811 - val_accuracy: 37.8788%\n",
            "Epoch 15/200\n",
            "26/26 - train_loss: 1.5549 - train_accuracy: 39.2255%                 - val_loss: 0.7875 - val_accuracy: 41.9192%\n",
            "Epoch 16/200\n",
            "26/26 - train_loss: 1.5618 - train_accuracy: 38.7258%                 - val_loss: 0.7866 - val_accuracy: 43.4343%\n",
            "Epoch 17/200\n",
            "26/26 - train_loss: 1.5584 - train_accuracy: 39.6002%                 - val_loss: 0.7854 - val_accuracy: 43.4343%\n",
            "Epoch 18/200\n",
            "26/26 - train_loss: 1.5445 - train_accuracy: 40.0375%                 - val_loss: 0.7797 - val_accuracy: 43.9394%\n",
            "Epoch 19/200\n",
            "26/26 - train_loss: 1.5461 - train_accuracy: 38.1012%                 - val_loss: 0.7778 - val_accuracy: 45.4545%\n",
            "Epoch 20/200\n",
            "26/26 - train_loss: 1.5325 - train_accuracy: 41.1618%                 - val_loss: 0.7772 - val_accuracy: 44.9495%\n",
            "Epoch 21/200\n",
            "26/26 - train_loss: 1.5195 - train_accuracy: 42.3485%                 - val_loss: 0.7691 - val_accuracy: 44.4444%\n",
            "Epoch 22/200\n",
            "26/26 - train_loss: 1.5856 - train_accuracy: 44.4722%                 - val_loss: 0.7577 - val_accuracy: 41.9192%\n",
            "Epoch 23/200\n",
            "26/26 - train_loss: 1.5236 - train_accuracy: 44.5347%                 - val_loss: 0.7566 - val_accuracy: 43.4343%\n",
            "Epoch 24/200\n",
            "26/26 - train_loss: 1.5024 - train_accuracy: 45.7214%                 - val_loss: 0.7593 - val_accuracy: 43.9394%\n",
            "Epoch 25/200\n",
            "26/26 - train_loss: 1.4956 - train_accuracy: 42.7233%                 - val_loss: 0.7620 - val_accuracy: 45.4545%\n",
            "Epoch 26/200\n",
            "26/26 - train_loss: 1.5051 - train_accuracy: 42.9731%                 - val_loss: 0.7701 - val_accuracy: 42.4242%\n",
            "Epoch 27/200\n",
            "26/26 - train_loss: 1.5072 - train_accuracy: 45.0968%                 - val_loss: 0.7692 - val_accuracy: 43.4343%\n",
            "Epoch 28/200\n",
            "26/26 - train_loss: 1.4814 - train_accuracy: 45.2217%                 - val_loss: 0.7655 - val_accuracy: 44.9495%\n",
            "Epoch 29/200\n",
            "26/26 - train_loss: 1.4901 - train_accuracy: 45.7839%                 - val_loss: 0.7602 - val_accuracy: 45.9596%\n",
            "Epoch 30/200\n",
            "26/26 - train_loss: 1.4820 - train_accuracy: 45.6590%                 - val_loss: 0.7553 - val_accuracy: 48.9899%\n",
            "Epoch 31/200\n",
            "26/26 - train_loss: 1.4928 - train_accuracy: 46.0962%                 - val_loss: 0.7343 - val_accuracy: 45.4545%\n",
            "Epoch 32/200\n",
            "26/26 - train_loss: 1.4666 - train_accuracy: 47.0956%                 - val_loss: 0.7432 - val_accuracy: 46.9697%\n",
            "Epoch 33/200\n",
            "26/26 - train_loss: 1.4642 - train_accuracy: 48.5946%                 - val_loss: 0.7508 - val_accuracy: 45.4545%\n",
            "Epoch 34/200\n",
            "26/26 - train_loss: 1.4764 - train_accuracy: 47.3454%                 - val_loss: 0.7489 - val_accuracy: 46.9697%\n",
            "Epoch 35/200\n",
            "26/26 - train_loss: 1.4606 - train_accuracy: 46.6583%                 - val_loss: 0.7475 - val_accuracy: 48.4848%\n",
            "Epoch 36/200\n",
            "26/26 - train_loss: 1.4508 - train_accuracy: 47.4703%                 - val_loss: 0.7524 - val_accuracy: 46.4646%\n",
            "Epoch 37/200\n",
            "26/26 - train_loss: 1.4459 - train_accuracy: 47.2205%                 - val_loss: 0.7456 - val_accuracy: 46.4646%\n",
            "Epoch 38/200\n",
            "26/26 - train_loss: 1.4583 - train_accuracy: 47.7826%                 - val_loss: 0.7467 - val_accuracy: 45.9596%\n",
            "Epoch 39/200\n",
            "26/26 - train_loss: 1.4398 - train_accuracy: 48.4697%                 - val_loss: 0.7364 - val_accuracy: 48.4848%\n",
            "Epoch 40/200\n",
            "26/26 - train_loss: 1.4315 - train_accuracy: 47.7826%                 - val_loss: 0.7336 - val_accuracy: 50.0000%\n",
            "Epoch 41/200\n",
            "26/26 - train_loss: 1.4198 - train_accuracy: 49.6565%                 - val_loss: 0.7074 - val_accuracy: 47.9798%\n",
            "Epoch 42/200\n",
            "26/26 - train_loss: 1.4237 - train_accuracy: 50.2186%                 - val_loss: 0.7048 - val_accuracy: 47.9798%\n",
            "Epoch 43/200\n",
            "26/26 - train_loss: 1.4292 - train_accuracy: 49.3442%                 - val_loss: 0.6975 - val_accuracy: 48.4848%\n",
            "Epoch 44/200\n",
            "26/26 - train_loss: 1.4159 - train_accuracy: 49.9688%                 - val_loss: 0.7023 - val_accuracy: 51.0101%\n",
            "Epoch 45/200\n",
            "26/26 - train_loss: 1.4343 - train_accuracy: 49.9688%                 - val_loss: 0.7135 - val_accuracy: 51.5152%\n",
            "Epoch 46/200\n",
            "26/26 - train_loss: 1.4080 - train_accuracy: 51.1555%                 - val_loss: 0.7142 - val_accuracy: 51.5152%\n",
            "Epoch 47/200\n",
            "26/26 - train_loss: 1.4201 - train_accuracy: 51.7177%                 - val_loss: 0.7114 - val_accuracy: 53.5354%\n",
            "Epoch 48/200\n",
            "26/26 - train_loss: 1.4011 - train_accuracy: 52.2798%                 - val_loss: 0.7109 - val_accuracy: 53.5354%\n",
            "Epoch 49/200\n",
            "26/26 - train_loss: 1.3963 - train_accuracy: 52.3423%                 - val_loss: 0.7052 - val_accuracy: 54.5455%\n",
            "Epoch 50/200\n",
            "26/26 - train_loss: 1.3833 - train_accuracy: 55.2780%                 - val_loss: 0.6772 - val_accuracy: 54.0404%\n",
            "Epoch 51/200\n",
            "26/26 - train_loss: 1.3791 - train_accuracy: 54.5909%                 - val_loss: 0.6822 - val_accuracy: 54.5455%\n",
            "Epoch 52/200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<div style=\"text-align: center\"> <font color=\"green\">GOOD LUCK WITH YOUR ASSIGNMENT 2!</font> </div>\n",
        "<div style=\"text-align: center\"> <font color=\"black\">END OF ASSIGNMENT</font> </div>"
      ],
      "metadata": {
        "id": "evYeSuXm-OkM"
      }
    }
  ]
}